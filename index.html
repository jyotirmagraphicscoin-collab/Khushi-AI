<!DOCTYPE html>
<html lang="hi">
<head>
  <meta charset="UTF-8" />
  <title>Khushi â€“ 3D Virtual Assistant</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <!-- Three.js + VRM -->
  <script src="https://cdn.jsdelivr.net/npm/three@0.158.0/build/three.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/three@0.158.0/examples/js/loaders/GLTFLoader.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@pixiv/three-vrm@2.0.6/lib/three-vrm.min.js"></script>

  <style>
    body {
      margin: 0;
      overflow: hidden;
      background: black;
      font-family: Arial, sans-serif;
      color: white;
    }

    #ui {
      position: fixed;
      bottom: 30px;
      width: 100%;
      text-align: center;
    }

    button {
      background: #ff4fa3;
      color: white;
      border: none;
      padding: 14px 26px;
      font-size: 18px;
      border-radius: 30px;
      cursor: pointer;
    }

    button:hover {
      background: #ff2d92;
    }

    #status {
      margin-top: 10px;
      font-size: 14px;
      color: #ffd1e8;
    }
  </style>
</head>

<body>
  <div id="ui">
    <button id="talkBtn">ðŸ’— Khushi se Baat Karein</button>
    <div id="status">Ready</div>
  </div>

<script>
/* =========================
   THREE.JS BASIC SETUP
========================= */
let scene = new THREE.Scene();
scene.background = new THREE.Color(0x000000);

let camera = new THREE.PerspectiveCamera(35, window.innerWidth/window.innerHeight, 0.1, 100);
camera.position.set(0, 1.4, 2.2);

let renderer = new THREE.WebGLRenderer({ antialias: true });
renderer.setSize(window.innerWidth, window.innerHeight);
renderer.setPixelRatio(window.devicePixelRatio);
document.body.appendChild(renderer.domElement);

const light = new THREE.DirectionalLight(0xffffff, 1.2);
light.position.set(1, 2, 3);
scene.add(light);

scene.add(new THREE.AmbientLight(0xffffff, 0.6));

/* =========================
   LOAD VRM MODEL
========================= */
let vrm;
const loader = new THREE.GLTFLoader();

THREE.VRMUtils.removeUnnecessaryVertices = true;
THREE.VRMUtils.removeUnnecessaryJoints = true;

loader.load("MODEL.vrm", (gltf) => {
  THREE.VRM.from(gltf).then((vrmModel) => {
    vrm = vrmModel;
    vrm.scene.rotation.y = 0; // face user
    scene.add(vrm.scene);
  });
});

/* =========================
   IDLE ANIMATION (Blink + Breath)
========================= */
let clock = new THREE.Clock();

function animate() {
  requestAnimationFrame(animate);

  if (vrm) {
    const t = clock.getElapsedTime();

    // Blink
    vrm.expressionManager.setValue("blink", Math.abs(Math.sin(t * 2)) < 0.05 ? 1 : 0);

    // Breathing
    vrm.scene.position.y = 0.02 * Math.sin(t * 1.5);
  }

  renderer.render(scene, camera);
}
animate();

/* =========================
   SPEECH RECOGNITION (HINDI)
========================= */
const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
const recognition = new SpeechRecognition();
recognition.lang = "hi-IN";
recognition.interimResults = false;

const status = document.getElementById("status");
const btn = document.getElementById("talkBtn");

btn.onclick = () => {
  recognition.start();
  status.innerText = "Khushi sunn rahi hai...";
};

recognition.onresult = (event) => {
  const userText = event.results[0][0].transcript;
  status.innerText = "Aap: " + userText;
  processBrain(userText);
};

/* =========================
   BRAIN SYSTEM (FLEXIBLE)
========================= */
async function processBrain(userInput) {

  /*
    OPTION A â€“ LOCAL BEST FRIEND BRAIN
    (No API, No Errors, Fully Offline)
  */
  const localReplies = {
    "kaise ho": "Main bilkul badiya hoon, aur aap?",
    "naam kya hai": "Mera naam Khushi hai.",
    "tum kya kar sakti ho": "Main aapki baatein sunn sakti hoon aur jawab de sakti hoon."
  };

  let reply = "Mujhe achha laga aapse baat karke.";

  for (let key in localReplies) {
    if (userInput.toLowerCase().includes(key)) {
      reply = localReplies[key];
    }
  }

  speak(reply);

  /*
    OPTION B â€“ API BRAIN (Future Ready)
    ---------------------------------
    Yahan aap OpenAI / Gemini call kar sakte ho:

    fetch("/api/chat", { method: "POST", body: JSON.stringify({ message: userInput }) })
  */
}

/* =========================
   SPEECH + LIP SYNC
========================= */
function speak(text) {
  const utter = new SpeechSynthesisUtterance(text);
  utter.lang = "hi-IN";

  utter.onstart = () => {
    lipInterval = setInterval(() => {
      if (vrm) vrm.expressionManager.setValue("aa", Math.random());
    }, 100);
  };

  utter.onend = () => {
    clearInterval(lipInterval);
    if (vrm) vrm.expressionManager.setValue("aa", 0);
  };

  speechSynthesis.speak(utter);
}
</script>

</body>
</html>
